{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "from pandas import Categorical, DataFrame, Series\n",
    "from seaborn import load_dataset\n",
    "from torch import float32, tensor\n",
    "\n",
    "from modugant.matrix import Matrix\n",
    "\n",
    "iris = DataFrame(load_dataset(\"iris\"))\n",
    "species = cast('Series[str]', iris.pop(\"species\"))\n",
    "iris['species'] = Categorical(species).codes\n",
    "data = Matrix.load(tensor(iris.values, dtype = float32), (150, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are 4 sizes that are used as type parameters for the needed protocols.\n",
    "## using the `Dim` class, we can ensure that our objects align in their dimensionalities.\n",
    "\n",
    "## C: The number of conditional variables\n",
    "\n",
    "from modugant.matrix import Dim\n",
    "\n",
    "## C: The number of conditional variables\n",
    "conditions = Dim[3](3)\n",
    "## L: The number of latent variables\n",
    "latent = Dim[10](10)\n",
    "## G: The number of generated features\n",
    "generated = Dim[7](7)\n",
    "## D: The number of real features to discriminate\n",
    "dim = Dim[7](7)\n",
    "## The batch size\n",
    "batch = Dim[512](512)\n",
    "\n",
    "category = Dim[3](3)\n",
    "normed = Dim[4](4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a simple Regimen class\n",
    "\n",
    "from typing import Tuple, override\n",
    "\n",
    "from modugant.protocols import Action, Regimen\n",
    "\n",
    "\n",
    "class SimpleRegimen(Regimen):\n",
    "    def __init__(self, batch: int, iterations: int) -> None:\n",
    "        self._batch = batch\n",
    "        self._iterations = iterations\n",
    "    @override\n",
    "    def command(self, iteration: int, loss: Tuple[float, float]) -> Tuple[Action, str]:\n",
    "        if iteration >= self._iterations:\n",
    "            return ('stop', 'Max iterations reached.')\n",
    "        else:\n",
    "            return ('continue', 'Continue training.')\n",
    "    @override\n",
    "    def report(self, iteration: int, action: Action, message: str, d_loss: float, g_loss: float) -> None:\n",
    "        if action == 'continue' and iteration % 10 == 0:\n",
    "            print(f'Iteration: {iteration}, D Loss: {d_loss}, G Loss: {g_loss}')\n",
    "        elif action != 'continue':\n",
    "            print(f'Iteration: {iteration}, D Loss: {d_loss}, G Loss: {g_loss}')\n",
    "            print(f'\\t{action}: {message}')\n",
    "    @override\n",
    "    def reset(self) -> None:\n",
    "        pass\n",
    "    @property\n",
    "    @override\n",
    "    def batch(self) -> int:\n",
    "        return self._batch\n",
    "    @property\n",
    "    @override\n",
    "    def k(self) -> int:\n",
    "        return 1\n",
    "    @property\n",
    "    @override\n",
    "    def d_factor(self) -> float:\n",
    "        return 1.0\n",
    "    @property\n",
    "    @override\n",
    "    def g_factor(self) -> float:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modugant.connectors import JointConnector\n",
    "from modugant.discriminators import FoldedDiscriminator, SmoothedDiscriminator\n",
    "from modugant.generators import ResidualGenerator\n",
    "from modugant.samplers.random import RandomSampler\n",
    "from modugant.transformers import CategoryTransformer, StandardizeTransformer\n",
    "\n",
    "generator = ResidualGenerator(\n",
    "    conditions,\n",
    "    latent,\n",
    "    generated,\n",
    "    steps = [256, 256],\n",
    "    learning = 0.0001,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "connector = JointConnector(\n",
    "    conditions,\n",
    "    generated,\n",
    "    dim,\n",
    "    transformers = (\n",
    "        StandardizeTransformer(\n",
    "            normed,\n",
    "            data = data,\n",
    "            index = [0, 1, 2, 3]\n",
    "        ),\n",
    "        CategoryTransformer(index = (4, category))\n",
    "    ),\n",
    "    sampler = RandomSampler(\n",
    "        data.shape[1],\n",
    "        data = data,\n",
    "        split = 0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "discriminator = SmoothedDiscriminator(\n",
    "    FoldedDiscriminator(\n",
    "        conditions,\n",
    "        dim,\n",
    "        group = 16,\n",
    "        steps = [256, 256],\n",
    "        lr = 0.0001\n",
    "    ),\n",
    "    factor = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, D Loss: 0.015230022370815277, G Loss: -0.08300692588090897\n",
      "Iteration: 10, D Loss: 0.0034142471849918365, G Loss: -0.11145349591970444\n",
      "Iteration: 20, D Loss: 0.006651170551776886, G Loss: -0.20655685663223267\n",
      "Iteration: 30, D Loss: 0.05562207102775574, G Loss: -0.2730565071105957\n",
      "Iteration: 40, D Loss: -0.022122129797935486, G Loss: -0.3504694402217865\n",
      "Iteration: 50, D Loss: 0.021930888295173645, G Loss: -0.36635181307792664\n",
      "Iteration: 60, D Loss: 0.012780040502548218, G Loss: -0.473486065864563\n",
      "Iteration: 70, D Loss: -0.08872607350349426, G Loss: -0.43231406807899475\n",
      "Iteration: 80, D Loss: -0.08668327331542969, G Loss: -0.4800696074962616\n",
      "Iteration: 90, D Loss: -0.0826062560081482, G Loss: -0.46301180124282837\n",
      "Iteration: 100, D Loss: -0.1896798312664032, G Loss: -0.6601606011390686\n",
      "Iteration: 110, D Loss: -0.07319486141204834, G Loss: -0.5775861144065857\n",
      "Iteration: 120, D Loss: -0.096417635679245, G Loss: -0.6934158205986023\n",
      "Iteration: 130, D Loss: -0.06752997636795044, G Loss: -0.7676402926445007\n",
      "Iteration: 140, D Loss: 0.03726479411125183, G Loss: -0.8750916123390198\n",
      "Iteration: 150, D Loss: -0.045386046171188354, G Loss: -0.9116645455360413\n",
      "Iteration: 160, D Loss: 0.012011826038360596, G Loss: -1.0485200881958008\n",
      "Iteration: 170, D Loss: -0.12273088097572327, G Loss: -0.683785617351532\n",
      "Iteration: 180, D Loss: -0.1341695785522461, G Loss: -0.8917945027351379\n",
      "Iteration: 190, D Loss: 0.002029716968536377, G Loss: -0.8665425777435303\n",
      "Iteration: 200, D Loss: -0.040989816188812256, G Loss: -0.881173849105835\n",
      "Iteration: 210, D Loss: -0.02625894546508789, G Loss: -0.580488920211792\n",
      "Iteration: 220, D Loss: -0.006311237812042236, G Loss: -0.8376020789146423\n",
      "Iteration: 230, D Loss: -0.030269652605056763, G Loss: -0.7456559538841248\n",
      "Iteration: 240, D Loss: 0.03987017273902893, G Loss: -0.8292120099067688\n",
      "Iteration: 250, D Loss: 0.047476768493652344, G Loss: -1.021519422531128\n",
      "Iteration: 260, D Loss: -0.007480978965759277, G Loss: -1.1237629652023315\n",
      "Iteration: 270, D Loss: -0.008967399597167969, G Loss: -1.0865907669067383\n",
      "Iteration: 280, D Loss: 0.058605194091796875, G Loss: -0.8311626315116882\n",
      "Iteration: 290, D Loss: 0.06559872627258301, G Loss: -0.8324115872383118\n",
      "Iteration: 300, D Loss: -0.2070089727640152, G Loss: -0.9619851112365723\n",
      "Iteration: 310, D Loss: -0.05969032645225525, G Loss: -0.8369086980819702\n",
      "Iteration: 320, D Loss: 0.20991525053977966, G Loss: -0.7996920347213745\n",
      "Iteration: 330, D Loss: 0.06679677963256836, G Loss: -1.2695337533950806\n",
      "Iteration: 340, D Loss: -0.09663781523704529, G Loss: -1.1627771854400635\n",
      "Iteration: 350, D Loss: 0.07810696959495544, G Loss: -0.7538034319877625\n",
      "Iteration: 360, D Loss: -0.16802120208740234, G Loss: -0.6066656112670898\n",
      "Iteration: 370, D Loss: -0.04125574231147766, G Loss: -0.8408647775650024\n",
      "Iteration: 380, D Loss: 0.08395364880561829, G Loss: -0.9910162091255188\n",
      "Iteration: 390, D Loss: 0.09544911980628967, G Loss: -1.1470433473587036\n",
      "Iteration: 400, D Loss: 0.1309589147567749, G Loss: -1.0194804668426514\n",
      "Iteration: 410, D Loss: -0.01151818037033081, G Loss: -0.6959134936332703\n",
      "Iteration: 420, D Loss: -0.1694861799478531, G Loss: -0.49398261308670044\n",
      "Iteration: 430, D Loss: 0.04762503504753113, G Loss: -0.3482666015625\n",
      "Iteration: 440, D Loss: 0.01955324411392212, G Loss: -0.7931215763092041\n",
      "Iteration: 450, D Loss: -0.2975503206253052, G Loss: -0.5504653453826904\n",
      "Iteration: 460, D Loss: -0.07936738431453705, G Loss: -0.5198562741279602\n",
      "Iteration: 470, D Loss: 0.0069852471351623535, G Loss: -0.26486629247665405\n",
      "Iteration: 480, D Loss: 0.007287740707397461, G Loss: -0.23330368101596832\n",
      "Iteration: 490, D Loss: -0.14652080833911896, G Loss: -0.2983783483505249\n",
      "Iteration: 500, D Loss: -0.24185101687908173, G Loss: 0.19893820583820343\n",
      "\tstop: Max iterations reached.\n"
     ]
    }
   ],
   "source": [
    "from modugant.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(generator, discriminator, connector)\n",
    "\n",
    "trainer.train(SimpleRegimen(batch, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[-1.3867, -0.9796, -0.5780, -0.0083,  3.2802, -2.8989, -3.1806],\n",
      "        [ 0.2897, -1.5002,  1.8807,  0.9896, -2.8921,  4.2539, -2.8045],\n",
      "        [ 0.9558, -0.5924,  1.6137,  1.1633, -2.6836, -2.5619,  3.5942]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.3867e+00, -9.7960e-01, -5.7801e-01, -8.2732e-03,  9.9638e-01,\n",
      "          2.0648e-03,  1.5580e-03],\n",
      "        [ 2.8967e-01, -1.5002e+00,  1.8807e+00,  9.8958e-01,  7.8672e-04,\n",
      "          9.9835e-01,  8.5874e-04],\n",
      "        [ 9.5575e-01, -5.9236e-01,  1.6137e+00,  1.1633e+00,  1.8701e-03,\n",
      "          2.1121e-03,  9.9602e-01]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "seeds = Matrix.load(\n",
    "    tensor([\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, 1.0, 0.0],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ]),\n",
    "    shape = (3, Dim[3](3))\n",
    ")\n",
    "\n",
    "with trainer.test():\n",
    "    fake = generator.sample(seeds)\n",
    "    prepared = connector.prepare(seeds, fake)\n",
    "    print(\n",
    "        seeds,\n",
    "        fake,\n",
    "        prepared,\n",
    "        sep = '\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[-0.4677, -0.5061,  0.8408,  1.8266, -0.4324, -0.2734, -0.8410],\n",
      "        [-1.1495,  1.1017, -0.8824, -1.3620, -0.1115, -1.1865, -0.6843],\n",
      "        [-0.2840, -0.1743, -0.2375, -0.0452,  0.2836, -0.4731, -0.6929]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.4677, -0.5061,  0.8408,  1.8266,  0.3525,  0.4133,  0.2343],\n",
      "        [-1.1495,  1.1017, -0.8824, -1.3620,  0.5249,  0.1791,  0.2960],\n",
      "        [-0.2840, -0.1743, -0.2375, -0.0452,  0.5418,  0.2542,  0.2040]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "seeds = Matrix.load(\n",
    "    tensor([\n",
    "        [0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0]\n",
    "    ]),\n",
    "    shape = (3, Dim[3](3))\n",
    ")\n",
    "\n",
    "with trainer.test():\n",
    "    fake = generator.sample(seeds)\n",
    "    prepared = connector.prepare(seeds, fake)\n",
    "    print(\n",
    "        seeds,\n",
    "        fake,\n",
    "        prepared,\n",
    "        sep = '\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
