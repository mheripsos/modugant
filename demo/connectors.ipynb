{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "from pandas import Categorical, DataFrame, Series\n",
    "from seaborn import load_dataset\n",
    "from torch import float32, tensor\n",
    "\n",
    "from modugant.matrix import Matrix\n",
    "\n",
    "iris = DataFrame(load_dataset(\"iris\"))\n",
    "species = cast('Series[str]', iris.pop(\"species\"))\n",
    "iris['species'] = Categorical(species).codes\n",
    "data = Matrix.load(tensor(iris.values, dtype = float32), (150, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are 4 sizes that are used as type parameters for the needed protocols.\n",
    "## using the `Dim` class, we can ensure that our objects align in their dimensionalities.\n",
    "\n",
    "## C: The number of conditional variables\n",
    "\n",
    "from modugant.matrix.dim import Dim\n",
    "\n",
    "conditions = Dim[0](0)\n",
    "## L: The number of latent variables\n",
    "latent = Dim[10](10)\n",
    "## G: The number of generated features\n",
    "generated = Dim[5](5)\n",
    "## D: The number of real features to discriminate\n",
    "dim = Dim[5](5)\n",
    "## The batch size\n",
    "batch = Dim[8](8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3000, 3.4000, 5.6000, 2.4000, 2.0000],\n",
      "        [5.7000, 2.9000, 4.2000, 1.3000, 1.0000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000, 0.0000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.3000, 0.0000],\n",
      "        [6.9000, 3.1000, 5.4000, 2.1000, 2.0000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000, 2.0000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000, 2.0000],\n",
      "        [5.1000, 3.3000, 1.7000, 0.5000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "## A `Connector` provides a connection between\n",
    "##   the real data source and the discriminator\n",
    "##   the generator and the discriminator\n",
    "\n",
    "## Instantiate a direct connector which makes no transformations between data/generation and the discriminator\n",
    "##   A connector may have a `Sampler` which is used to sample from the real data source\n",
    "\n",
    "from modugant.connectors import DirectConnector\n",
    "from modugant.samplers import RandomSampler\n",
    "\n",
    "dim = Dim[5](5)\n",
    "batch = Dim[8](8)\n",
    "\n",
    "connector = DirectConnector(\n",
    "    dim,\n",
    "    sampler = RandomSampler(\n",
    "        dim,\n",
    "        data,\n",
    "        0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "print(connector.sample(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.9000, 3.2000, 4.8000, 1.8000, 1.0000],\n",
      "        [7.0000, 3.2000, 4.7000, 1.4000, 1.0000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000, 0.0000],\n",
      "        [4.8000, 3.4000, 1.9000, 0.2000, 0.0000],\n",
      "        [4.4000, 3.2000, 1.3000, 0.2000, 0.0000],\n",
      "        [5.1000, 2.5000, 3.0000, 1.1000, 1.0000],\n",
      "        [5.1000, 3.3000, 1.7000, 0.5000, 0.0000],\n",
      "        [5.5000, 2.4000, 3.7000, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "## Use an iterating `Sampler` instead\n",
    "\n",
    "from modugant.samplers import IteratingSampler\n",
    "\n",
    "connector = DirectConnector(\n",
    "    dim,\n",
    "    sampler = IteratingSampler(\n",
    "        dim,\n",
    "        data,\n",
    "        0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "print(connector.sample(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.1000, 3.5000, 1.4000, 0.2000, 0.0000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000, 0.0000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000, 0.0000],\n",
      "        [4.6000, 3.1000, 1.5000, 0.2000, 0.0000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000, 0.0000],\n",
      "        [5.4000, 3.9000, 1.7000, 0.4000, 0.0000],\n",
      "        [4.6000, 3.4000, 1.4000, 0.3000, 0.0000],\n",
      "        [5.0000, 3.4000, 1.5000, 0.2000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "## Create and use a custom sampler\n",
    "\n",
    "from typing import override\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from modugant.matrix import Matrix\n",
    "from modugant.matrix.index import Index\n",
    "from modugant.matrix.ops import zeros\n",
    "from modugant.protocols import Sampler\n",
    "\n",
    "\n",
    "class CustomSampler[D: int](Sampler[D]):\n",
    "    def __init__(self, dim: D, data: Tensor):\n",
    "        self._outputs = dim\n",
    "        self.__data = Matrix.load(data, (data.shape[0], dim))\n",
    "        self.__index = 0\n",
    "    @override\n",
    "    def sample[N: int](self, batch: N) -> Matrix[N, D]:\n",
    "        if self.__index + batch > self.__data.shape[0]:\n",
    "            self.__index = 0\n",
    "        sample = Index.slice(self.__index, batch)\n",
    "        return self.__data[sample, ...]\n",
    "    @override\n",
    "    def restart(self) -> None:\n",
    "        self.__index = 0\n",
    "    @property\n",
    "    @override\n",
    "    def holdout(self) -> Matrix[int, D]:\n",
    "        return zeros((0, self._outputs))\n",
    "\n",
    "dim = Dim[5](5)\n",
    "batch = Dim[8](8)\n",
    "\n",
    "connector = DirectConnector(\n",
    "    dim,\n",
    "    sampler = CustomSampler(dim, data)\n",
    ")\n",
    "\n",
    "print(connector.sample(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2939, -0.5904,  0.6469,  1.0504],\n",
      "        [-0.8977,  1.7039, -1.0525, -1.0487],\n",
      "        [-0.7769,  2.3922, -1.2791, -1.4422],\n",
      "        [-0.7769,  2.3922, -1.2791, -1.4422],\n",
      "        [ 1.2761,  0.3273,  1.1001,  1.4440],\n",
      "        [ 1.1553,  0.3273,  1.2134,  1.4440],\n",
      "        [-0.8977,  1.7039, -1.2225, -1.3111],\n",
      "        [ 0.5515, -0.8198,  0.6469,  0.7880]])\n"
     ]
    }
   ],
   "source": [
    "## Use a `LoadedSampler`` with a `Loader` to transform the data before sampling\n",
    "\n",
    "## Use normalization on data index 0, 1, 2, 3\n",
    "\n",
    "from modugant.loaders import StandardizeLoader\n",
    "from modugant.samplers import LoadingSampler\n",
    "\n",
    "dim = Dim[5](5) # dimension sampled\n",
    "normed = Dim[4](4) # dimension loaded from sampler\n",
    "batch = Dim[8](8)\n",
    "\n",
    "connector = DirectConnector(\n",
    "    normed,\n",
    "    sampler = LoadingSampler(\n",
    "        sampler = RandomSampler(\n",
    "            dim,\n",
    "            data,\n",
    "            0.8\n",
    "        ),\n",
    "        loader = StandardizeLoader(\n",
    "            normed,\n",
    "            data,\n",
    "            index = [0, 1, 2, 3]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(connector.sample(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9386e-01, -8.1982e-01,  2.5038e-01,  1.3207e-01],\n",
      "        [-1.2600e+00,  7.8617e-01, -1.0525e+00, -1.3111e+00],\n",
      "        [ 6.7225e-01,  3.2732e-01,  4.2033e-01,  3.9445e-01],\n",
      "        [ 1.0345e+00,  9.7889e-02,  5.3362e-01,  3.9445e-01],\n",
      "        [-1.1392e+00, -1.5081e+00, -2.5945e-01, -2.6151e-01],\n",
      "        [-1.5015e+00,  1.2450e+00, -1.5623e+00, -1.3111e+00],\n",
      "        [-1.1392e+00, -1.3154e-01, -1.3358e+00, -1.3111e+00],\n",
      "        [-1.8638e+00, -1.3154e-01, -1.5057e+00, -1.4422e+00],\n",
      "        [-1.7309e-01,  1.7039e+00, -1.1658e+00, -1.1799e+00],\n",
      "        [-5.2330e-02, -8.1982e-01,  8.0440e-02,  8.7455e-04]])\n"
     ]
    }
   ],
   "source": [
    "## Create the same using the `Loader` separately\n",
    "\n",
    "dim = Dim[5](5) # dimension sampled\n",
    "normed = Dim[4](4) # dimension loaded from sampler\n",
    "batch = Dim[8](8)\n",
    "\n",
    "connector = DirectConnector(\n",
    "    normed,\n",
    "    sampler = RandomSampler(\n",
    "        dim,\n",
    "        data,\n",
    "        0.8\n",
    "    ),\n",
    "    loader = StandardizeLoader(\n",
    "        normed,\n",
    "        data,\n",
    "        index = [0, 1, 2, 3]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(connector.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.3538e-01, -1.3154e-01,  4.2033e-01,  3.9445e-01,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  5.4000e+00,  3.0000e+00,  4.5000e+00,\n",
      "          1.5000e+00],\n",
      "        [-4.1462e-01, -1.0493e+00,  3.6368e-01,  8.7455e-04,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  5.5000e+00,  2.6000e+00,  4.4000e+00,\n",
      "          1.2000e+00],\n",
      "        [ 1.1553e+00, -5.9039e-01,  5.9027e-01,  2.6326e-01,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  6.8000e+00,  2.8000e+00,  4.8000e+00,\n",
      "          1.4000e+00],\n",
      "        [ 5.5149e-01, -3.6097e-01,  1.0434e+00,  7.8803e-01,  0.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  6.3000e+00,  2.9000e+00,  5.6000e+00,\n",
      "          1.8000e+00],\n",
      "        [ 2.2422e+00, -1.3154e-01,  1.3267e+00,  1.4440e+00,  0.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  7.7000e+00,  3.0000e+00,  6.1000e+00,\n",
      "          2.3000e+00],\n",
      "        [ 7.9301e-01, -5.9039e-01,  4.7697e-01,  3.9445e-01,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  6.5000e+00,  2.8000e+00,  4.6000e+00,\n",
      "          1.5000e+00],\n",
      "        [ 1.7591e+00, -3.6097e-01,  1.4400e+00,  7.8803e-01,  0.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  7.3000e+00,  2.9000e+00,  6.3000e+00,\n",
      "          1.8000e+00],\n",
      "        [ 3.0996e-01, -1.3154e-01,  4.7697e-01,  2.6326e-01,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  6.1000e+00,  3.0000e+00,  4.6000e+00,\n",
      "          1.4000e+00]])\n"
     ]
    }
   ],
   "source": [
    "## Combine multiple Loaders for different portions of the underlying data\n",
    "\n",
    "## Normalize the data at index 0, 1, 2, 3\n",
    "## One-Hot Category encode the data at index 4\n",
    "## Directly load the data at index 0 through 4\n",
    "\n",
    "from modugant.loaders import CategoryLoader, DirectLoader, JointLoader\n",
    "\n",
    "sampled = Dim[5](5) # dimension sampled\n",
    "normed = Dim[4](4) # dimension normalized\n",
    "direct = Dim[4](4) # dimension directly loaded\n",
    "category = Dim[3](3) # dimension category loaded\n",
    "outputs = Dim[11](11) # total dimension loaded\n",
    "batch = Dim[8](8)\n",
    "\n",
    "connector = DirectConnector(\n",
    "    outputs,\n",
    "    sampler = RandomSampler(\n",
    "        sampled,\n",
    "        data,\n",
    "        0.8\n",
    "    ),\n",
    "    loader = JointLoader(\n",
    "        outputs,\n",
    "        loaders = (\n",
    "            StandardizeLoader(\n",
    "                normed,\n",
    "                data,\n",
    "                index = [0, 1, 2, 3]\n",
    "            ),\n",
    "            CategoryLoader(\n",
    "                category,\n",
    "                index = [(4, 3)]\n",
    "            ),\n",
    "            DirectLoader(\n",
    "                direct,\n",
    "                index = [(0, 4)]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(connector.sample(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1392,  1.2450, -1.3358, -1.4422,  1.0000,  0.0000,  0.0000, -0.9433,\n",
      "          0.5427, -2.3580, -1.0993],\n",
      "        [-1.7430, -0.1315, -1.3924, -1.3111,  1.0000,  0.0000,  0.0000, -1.4433,\n",
      "         -0.0573, -2.4580, -0.9993],\n",
      "        [-0.8977,  0.7862, -1.2791, -1.3111,  1.0000,  0.0000,  0.0000, -0.7433,\n",
      "          0.3427, -2.2580, -0.9993],\n",
      "        [ 0.1892, -0.8198,  0.7602,  0.5256,  0.0000,  1.0000,  0.0000,  0.1567,\n",
      "         -0.3573,  1.3420,  0.4007],\n",
      "        [ 0.5515, -1.7375,  0.3637,  0.1321,  0.0000,  1.0000,  0.0000,  0.4567,\n",
      "         -0.7573,  0.6420,  0.1007],\n",
      "        [ 2.2422, -0.5904,  1.6666,  1.0504,  0.0000,  0.0000,  1.0000,  1.8567,\n",
      "         -0.2573,  2.9420,  0.8007],\n",
      "        [ 1.2761,  0.0979,  0.6469,  0.3945,  0.0000,  1.0000,  0.0000,  1.0567,\n",
      "          0.0427,  1.1420,  0.3007],\n",
      "        [-1.0184,  1.2450, -1.3358, -1.3111,  1.0000,  0.0000,  0.0000, -0.8433,\n",
      "          0.5427, -2.3580, -0.9993]])\n"
     ]
    }
   ],
   "source": [
    "## Create a custom `Loader` that fully implements the `Loader` protocol\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from modugant.matrix import Index\n",
    "from modugant.protocols import Loader\n",
    "\n",
    "\n",
    "class ZeroMeanLoader[D: int](Loader[D]):\n",
    "    def __init__(self, dim: D, data: Tensor, index: List[int]):\n",
    "        self._outputs = dim\n",
    "        matrix = Matrix.load(data, (data.shape[0], data.shape[1]))\n",
    "        self._index = Index.load(index, dim)\n",
    "        self._mean = matrix[..., self._index].mean(dim = 0, keepdim = True)\n",
    "    @override\n",
    "    def load[N: int](self, data: Matrix[N, int]) -> Matrix[N, D]:\n",
    "        return data[..., self._index] - self._mean\n",
    "\n",
    "sampled = Dim[5](5) # dimension sampled\n",
    "normed = Dim[4](4) # dimension normalized\n",
    "centered = Dim[4](4) # dimension zero-mean loaded\n",
    "category = Dim[3](3) # dimension category loaded\n",
    "outputs = Dim[11](11) # total dimension loaded\n",
    "batch = Dim[8](8)\n",
    "\n",
    "connector = DirectConnector(\n",
    "    outputs,\n",
    "    sampler = RandomSampler(\n",
    "        sampled,\n",
    "        data,\n",
    "        0.8\n",
    "    ),\n",
    "    loader = JointLoader(\n",
    "        outputs,\n",
    "        loaders = (\n",
    "            StandardizeLoader(\n",
    "                normed,\n",
    "                data,\n",
    "                index = [0, 1, 2, 3]\n",
    "            ),\n",
    "            CategoryLoader(\n",
    "                category,\n",
    "                index = [(4, 3)]\n",
    "            ),\n",
    "            ZeroMeanLoader(\n",
    "                centered,\n",
    "                data,\n",
    "                index = [0, 1, 2, 3]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(connector.sample(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9138, -0.3610,  0.4770,  0.1321,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.8799, -0.5904,  1.3267,  0.9192,  0.0000,  0.0000,  1.0000],\n",
      "        [-0.0523, -0.8198,  0.1937, -0.2615,  0.0000,  1.0000,  0.0000],\n",
      "        [-1.5015,  1.2450, -1.5623, -1.3111,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.2939, -0.5904,  0.6469,  1.0504,  0.0000,  0.0000,  1.0000],\n",
      "        [-1.2600, -0.1315, -1.3358, -1.1799,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.1731,  1.7039, -1.1658, -1.1799,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.2761,  0.0979,  0.6469,  0.3945,  0.0000,  1.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "## Use a `ComposedConnector` to further modularize\n",
    "\n",
    "## A connector can be composed from the following modules\n",
    "##   `Conditioner`: a class to create and use conditions\n",
    "##   `Interceptor`: a class to transform generated data to fit the discriminator\n",
    "##   `Updater`: a class to add additional loss to the generator\n",
    "##   `Sampler`: a class to sample from the real data source\n",
    "##   `Loader`: Optionally, a class to transform the real data after sampling\n",
    "\n",
    "## Recreate the previous connector using a `ComposedConnector`\n",
    "\n",
    "from modugant.conditioners import NoneConditioner\n",
    "from modugant.connectors import ComposedConnector\n",
    "from modugant.interceptors import DirectInterceptor\n",
    "from modugant.updaters import StaticUpdater\n",
    "\n",
    "conditions = Dim.zero() ## no conditions, same as Dim[0](0)\n",
    "dim = Dim[7](7)\n",
    "normed = Dim[4](4)\n",
    "category = Dim[3](3)\n",
    "batch = Dim[8](8)\n",
    "\n",
    "connector = ComposedConnector(\n",
    "    conditioner = NoneConditioner(dim),\n",
    "    interceptor = DirectInterceptor(conditions, dim),\n",
    "    updater = StaticUpdater(Dim.zero(), dim),\n",
    "    sampler = LoadingSampler(\n",
    "        sampler = RandomSampler(\n",
    "            data.shape[1],\n",
    "            data,\n",
    "            0.8\n",
    "        ),\n",
    "        loader = JointLoader(\n",
    "            dim,\n",
    "            loaders = (\n",
    "                StandardizeLoader(\n",
    "                    normed,\n",
    "                    data,\n",
    "                    index = [0, 1, 2, 3]\n",
    "                ),\n",
    "                CategoryLoader(\n",
    "                    category,\n",
    "                    index = [(4, 3)]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(connector.sample(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4880, -0.7226,  0.1877],\n",
      "        [ 0.4701, -0.5223, -0.5036],\n",
      "        [ 0.2934, -0.8172,  0.1433],\n",
      "        [ 0.2766, -0.4117, -0.2942],\n",
      "        [ 0.5163, -0.1524, -0.4131],\n",
      "        [-0.2032, -0.5554, -0.4482],\n",
      "        [ 0.5067, -0.3434, -0.5752],\n",
      "        [ 0.5616, -0.7842,  0.1741],\n",
      "        [ 0.1884, -0.4760, -0.1681],\n",
      "        [ 0.5014, -0.6263,  0.5028]], grad_fn=<TanhBackward0>)\n",
      "tensor([[0.2662, 0.2105, 0.5232],\n",
      "        [0.5719, 0.2120, 0.2160],\n",
      "        [0.4566, 0.1504, 0.3930],\n",
      "        [0.4837, 0.2430, 0.2733],\n",
      "        [0.5243, 0.2687, 0.2070],\n",
      "        [0.4023, 0.2829, 0.3149],\n",
      "        [0.5662, 0.2420, 0.1919],\n",
      "        [0.5157, 0.1342, 0.3500],\n",
      "        [0.4515, 0.2324, 0.3161],\n",
      "        [0.4301, 0.1393, 0.4307]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Use a SoftmaxInterceptor on the category columns\n",
    "\n",
    "from modugant.generators import ResidualGenerator\n",
    "from modugant.interceptors import SoftmaxInterceptor\n",
    "\n",
    "conditions = Dim[0](0)\n",
    "latent = Dim[3](3)\n",
    "generated = Dim[3](3)\n",
    "dim = Dim[3](3)\n",
    "\n",
    "generator = ResidualGenerator(\n",
    "    conditions,\n",
    "    latent,\n",
    "    generated,\n",
    "    steps = [2],\n",
    "    learning = 0.01,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "connector = ComposedConnector(\n",
    "    conditioner = NoneConditioner(dim),\n",
    "    interceptor = SoftmaxInterceptor(conditions, generated, dim, index = [(0, 3)]),\n",
    "    updater = StaticUpdater(Dim.zero(), dim),\n",
    "    sampler = LoadingSampler(\n",
    "        sampler = RandomSampler(\n",
    "            data.shape[1],\n",
    "            data,\n",
    "            0.8\n",
    "        ),\n",
    "        loader = CategoryLoader(\n",
    "            category,\n",
    "            index = [(4, dim)]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# create empty conditions\n",
    "condition = zeros((10, conditions), dtype = float32)\n",
    "# sample from the generator\n",
    "fake = generator.sample(condition)\n",
    "# prepare the fake data for the discriminator\n",
    "prepared = connector.prepare(condition, fake)\n",
    "\n",
    "print(fake, prepared, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1846, -0.1248, -0.0965, -0.0767,  0.1525,  0.1945, -0.1127],\n",
      "        [-0.7863, -0.6746, -0.2433,  0.1546, -0.2298, -0.2362,  0.4956],\n",
      "        [ 0.3876,  0.7162, -0.2730,  0.9713,  0.2785,  0.3914,  0.0925],\n",
      "        [ 0.5010,  0.5405,  0.4390, -0.1480, -0.1599,  0.4777, -0.1890],\n",
      "        [-0.2299, -0.1494, -0.2174,  0.4210, -0.1965, -0.3212,  0.3101],\n",
      "        [-0.4350, -0.6290, -0.8216, -0.2967,  0.3459, -0.3796, -0.6841],\n",
      "        [-0.4678, -0.5655, -0.6928,  0.8577,  0.6438,  0.0127, -0.1223],\n",
      "        [-0.5714, -0.3336, -0.6750,  0.6879, -0.3701, -0.3952,  0.3175]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([[-0.1846, -0.1248, -0.0965, -0.0767,  0.3559,  0.3711,  0.2730],\n",
      "        [-0.7863, -0.6746, -0.2433,  0.1546,  0.2464,  0.2448,  0.5089],\n",
      "        [ 0.3876,  0.7162, -0.2730,  0.9713,  0.3390,  0.3795,  0.2815],\n",
      "        [ 0.5010,  0.5405,  0.4390, -0.1480,  0.2588,  0.4897,  0.2514],\n",
      "        [-0.2299, -0.1494, -0.2174,  0.4210,  0.2823,  0.2492,  0.4685],\n",
      "        [-0.4350, -0.6290, -0.8216, -0.2967,  0.5431,  0.2629,  0.1939],\n",
      "        [-0.4678, -0.5655, -0.6928,  0.8577,  0.5008,  0.2664,  0.2328],\n",
      "        [-0.5714, -0.3336, -0.6750,  0.6879,  0.2523,  0.2460,  0.5017]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## The previous connector only intercepts and prepares the category data with a `SoftmaxInterceptor`\n",
    "## Use a `JointInterceptor` to combine a `DirectInterceptor` and a `SoftmaxInterceptor`\n",
    "\n",
    "from modugant.interceptors import JointInterceptor\n",
    "\n",
    "conditions = Dim[0](0)\n",
    "latent = Dim[5](5)\n",
    "generated = Dim[7](7)\n",
    "normed = Dim[4](4)\n",
    "category = Dim[3](3)\n",
    "dim = Dim[7](7)\n",
    "\n",
    "generator = ResidualGenerator(\n",
    "    conditions,\n",
    "    latent,\n",
    "    generated,\n",
    "    steps = [2],\n",
    "    learning = 0.01,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "## A `JointInterceptor` will be fed parallel streams of data according to the dimension of each\n",
    "## The SoftmaxInterceptor below will be given a `category` sized block that occurs after the `normed` sized block\n",
    "## So the index for the SoftmaxInterceptor is [(0, 3)]\n",
    "\n",
    "connector = ComposedConnector(\n",
    "    conditioner = NoneConditioner(dim),\n",
    "    interceptor = JointInterceptor(\n",
    "        conditions, # conditions + conditions = conditions\n",
    "        generated, # normed + category = generated\n",
    "        dim, # normed + category = dim\n",
    "        interceptors = (\n",
    "            DirectInterceptor(conditions, normed),\n",
    "            SoftmaxInterceptor(conditions, category, category, index = [(0, 3)])\n",
    "        )\n",
    "    ),\n",
    "    updater = StaticUpdater(conditions, generated),\n",
    "    sampler = LoadingSampler(\n",
    "        sampler = RandomSampler(\n",
    "            data.shape[1],\n",
    "            data,\n",
    "            0.8\n",
    "        ),\n",
    "        loader = JointLoader(\n",
    "            dim,\n",
    "            loaders = (\n",
    "                StandardizeLoader(\n",
    "                    normed,\n",
    "                    data,\n",
    "                    index = [0, 1, 2, 3]\n",
    "                ),\n",
    "                CategoryLoader(\n",
    "                    category,\n",
    "                    index = [(4, 3)]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "condition = zeros((batch, Dim.zero()))\n",
    "fake = generator.sample(condition)\n",
    "\n",
    "prepared = connector.prepare(condition, fake)\n",
    "\n",
    "print(fake, prepared, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.]])\n",
      "tensor([[-0.0370, -0.3423,  0.0152,  0.2753,  0.5452,  0.4443,  0.1779],\n",
      "        [-0.1001,  0.0919, -0.0498,  0.4598,  0.0197,  0.2885,  0.1762],\n",
      "        [-0.4840, -0.5182,  0.4320,  0.2837,  0.2495,  0.4685,  0.2934],\n",
      "        [-0.0868,  0.3148, -0.3744,  0.5102,  0.2413,  0.4369, -0.3273],\n",
      "        [-0.5972,  0.0771,  0.2790,  0.5353,  0.5704,  0.0636,  0.2219],\n",
      "        [-0.3654, -0.3540,  0.3552,  0.2203,  0.1712,  0.4803,  0.4983],\n",
      "        [ 0.0132, -0.4928,  0.5045, -0.1473,  0.6535, -0.3288,  0.3369],\n",
      "        [ 0.0888,  0.0599, -0.2924,  0.4698,  0.0919,  0.5149, -0.3266]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([[-0.0370, -0.3423,  0.0152,  0.2753,  0.3851,  0.3481,  0.2667],\n",
      "        [-0.1001,  0.0919, -0.0498,  0.4598,  0.2875,  0.3762,  0.3362],\n",
      "        [-0.4840, -0.5182,  0.4320,  0.2837,  0.3040,  0.3784,  0.3176],\n",
      "        [-0.0868,  0.3148, -0.3744,  0.5102,  0.3594,  0.4371,  0.2035],\n",
      "        [-0.5972,  0.0771,  0.2790,  0.5353,  0.4332,  0.2610,  0.3058],\n",
      "        [-0.3654, -0.3540,  0.3552,  0.2203,  0.2667,  0.3633,  0.3699],\n",
      "        [ 0.0132, -0.4928,  0.5045, -0.1473,  0.4755,  0.1780,  0.3465],\n",
      "        [ 0.0888,  0.0599, -0.2924,  0.4698,  0.3140,  0.4793,  0.2066]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Create and use conditions\n",
    "\n",
    "from modugant.conditioners import CategoryConditioner\n",
    "\n",
    "conditions = Dim[3](3)\n",
    "latent = Dim[5](5)\n",
    "generated = Dim[7](7)\n",
    "normed = Dim[4](4)\n",
    "category = Dim[3](3)\n",
    "dim = Dim[7](7)\n",
    "\n",
    "generator = ResidualGenerator(\n",
    "    conditions,\n",
    "    latent,\n",
    "    generated,\n",
    "    steps = [5, 5, 5],\n",
    "    learning = 0.01,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "# Conditions are also fed in paralle tracks into the interceptor\n",
    "# Where as we were able to use `conditions = 0 => conditions + conditions = conditions` in the previous example\n",
    "# We now need to apportion the conditions among the joint blocks\n",
    "\n",
    "connector = ComposedConnector(\n",
    "    conditioner = CategoryConditioner(\n",
    "        conditions,\n",
    "        dim,\n",
    "        index = [(4, 3)], # index is based on entire data block\n",
    "        samples = 1 # sample a single category\n",
    "    ),\n",
    "    interceptor = JointInterceptor(\n",
    "        conditions,\n",
    "        generated,\n",
    "        dim,\n",
    "        interceptors = (\n",
    "            DirectInterceptor(Dim.zero(), normed), # categories are also fed in parallel tracks\n",
    "            SoftmaxInterceptor(conditions, category, category, index = [(0, 3)]) # index is based on Joint sub blocks\n",
    "        )\n",
    "    ),\n",
    "    updater = StaticUpdater(conditions, generated),\n",
    "    sampler = LoadingSampler(\n",
    "        sampler = RandomSampler(\n",
    "            data.shape[1],\n",
    "            data,\n",
    "            0.8\n",
    "        ),\n",
    "        loader = JointLoader(\n",
    "            dim,\n",
    "            loaders = (\n",
    "                StandardizeLoader(\n",
    "                    normed,\n",
    "                    data,\n",
    "                    index = [0, 1, 2, 3]\n",
    "                ),\n",
    "                CategoryLoader(\n",
    "                    category,\n",
    "                    index = [(4, 3)]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "real = connector.sample(batch)\n",
    "condition = connector.condition(real)\n",
    "fake = generator.sample(condition)\n",
    "prepared = connector.prepare(condition, fake)\n",
    "\n",
    "print(condition, fake, prepared, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "tensor([[-0.1266,  0.2505,  0.2577,  0.4111,  0.2390,  0.3971,  0.2635],\n",
      "        [ 0.0952, -0.0261,  0.0788, -0.0125,  0.0384,  0.2619,  0.1556],\n",
      "        [-0.0013,  0.3657,  0.4933,  0.3548,  0.1554, -0.5372,  0.3768],\n",
      "        [ 0.0239, -0.1403, -0.0917, -0.0412,  0.3303, -0.1760,  0.3304],\n",
      "        [ 0.0998,  0.2638,  0.4057,  0.0728, -0.0479,  0.1167,  0.0389],\n",
      "        [ 0.1447, -0.2930,  0.2716, -0.3217,  0.0992, -0.0804,  0.0769],\n",
      "        [ 0.1895, -0.1140, -0.1931, -0.1650,  0.3327,  0.0480,  0.2447],\n",
      "        [ 0.2285, -0.2333,  0.0038,  0.2437,  0.1796,  0.5685, -0.1218]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([[-0.1266,  0.2505,  0.2577,  0.4111,  0.3129,  0.3665,  0.3206],\n",
      "        [ 0.0952, -0.0261,  0.0788, -0.0125,  0.2963,  0.3705,  0.3331],\n",
      "        [-0.0013,  0.3657,  0.4933,  0.3548,  0.3639,  0.1821,  0.4541],\n",
      "        [ 0.0239, -0.1403, -0.0917, -0.0412,  0.3842,  0.2316,  0.3842],\n",
      "        [ 0.0998,  0.2638,  0.4057,  0.0728,  0.3058,  0.3606,  0.3336],\n",
      "        [ 0.1447, -0.2930,  0.2716, -0.3217,  0.3554,  0.2970,  0.3476],\n",
      "        [ 0.1895, -0.1140, -0.1931, -0.1650,  0.3748,  0.2819,  0.3432],\n",
      "        [ 0.2285, -0.2333,  0.0038,  0.2437,  0.3110,  0.4589,  0.2301]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Use a `PooledInterceptor` to maintain a single track\n",
    "\n",
    "from modugant.conditioners import CategoryConditioner\n",
    "from modugant.interceptors import PooledInterceptor, SubsetInterceptor\n",
    "\n",
    "conditions = Dim[3](3)\n",
    "latent = Dim[5](5)\n",
    "generated = Dim[7](7)\n",
    "normed = Dim[4](4)\n",
    "category = Dim[3](3)\n",
    "dim = Dim[7](7)\n",
    "\n",
    "generator = ResidualGenerator(\n",
    "    conditions,\n",
    "    latent,\n",
    "    generated,\n",
    "    steps = [5, 5, 5],\n",
    "    learning = 0.01,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "# The `PooledInterceptor` will maintain a single track of data, so the indices and parameters are offset\n",
    "# The `SubsetInterceptor` will subset the columns down to the first 4 of the single track\n",
    "# whereas the `DirectInterceptor` passed forward all of its individual parallel track\n",
    "\n",
    "connector = ComposedConnector(\n",
    "    conditioner = CategoryConditioner(\n",
    "        conditions,\n",
    "        dim,\n",
    "        index = [(4, 3)], # index is based on entire data block\n",
    "        samples = 1 # sample a single category\n",
    "    ),\n",
    "    interceptor = PooledInterceptor(\n",
    "        conditions,\n",
    "        generated,\n",
    "        dim,\n",
    "        interceptors = (\n",
    "            SubsetInterceptor(conditions, generated, normed, index = [0, 1, 2, 3]),\n",
    "            SoftmaxInterceptor(conditions, generated, category, index = [(4, 3)]) # the category starts at index 4\n",
    "        )\n",
    "    ),\n",
    "    updater = StaticUpdater(conditions, generated),\n",
    "    sampler = LoadingSampler(\n",
    "        sampler = RandomSampler(\n",
    "            data.shape[1],\n",
    "            data,\n",
    "            0.8\n",
    "        ),\n",
    "        loader = JointLoader(\n",
    "            dim,\n",
    "            loaders = (\n",
    "                StandardizeLoader(\n",
    "                    normed,\n",
    "                    data,\n",
    "                    index = [0, 1, 2, 3]\n",
    "                ),\n",
    "                CategoryLoader(\n",
    "                    category,\n",
    "                    index = [(4, 3)]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "real = connector.sample(batch)\n",
    "condition = connector.condition(real)\n",
    "fake = generator.sample(condition)\n",
    "prepared = connector.prepare(condition, fake)\n",
    "\n",
    "print(condition, fake, prepared, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "tensor([[-0.7378, -0.0486, -0.5129, -0.6843, -0.6138, -0.1067,  0.4269],\n",
      "        [ 0.8382, -0.3806,  0.1823, -0.0278,  0.7078, -0.8477, -0.4894],\n",
      "        [ 0.1514, -0.3090, -0.0240, -0.7253, -0.3106, -0.7019,  0.5350],\n",
      "        [ 0.4871, -0.2036, -0.2685, -0.0137,  0.4144, -0.6781,  0.4024],\n",
      "        [ 0.1322, -0.0349, -0.2672,  0.1477, -0.4560,  0.1746, -0.1377],\n",
      "        [ 0.1769,  0.3874,  0.0355,  0.2355,  0.4388, -0.4561, -0.5445],\n",
      "        [-0.9239,  0.6723, -0.5012, -0.5903,  0.0074,  0.3382, -0.6351],\n",
      "        [-0.2162,  0.1264, -0.1182, -0.4310, -0.1877, -0.0890, -0.1409]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([[1.5261]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Use an updater to calculate cross entropy of the generated conditions\n",
    "\n",
    "from modugant.updaters import EntropyUpdater\n",
    "\n",
    "generator = ResidualGenerator(\n",
    "    conditions,\n",
    "    latent,\n",
    "    generated,\n",
    "    steps = [5, 5, 5],\n",
    "    learning = 0.01,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "connector = ComposedConnector(\n",
    "    conditioner = CategoryConditioner(\n",
    "        conditions,\n",
    "        dim,\n",
    "        index = [(4, 3)],\n",
    "        samples = 1\n",
    "    ),\n",
    "    interceptor = PooledInterceptor(\n",
    "        conditions,\n",
    "        generated,\n",
    "        dim,\n",
    "        interceptors = (\n",
    "            SubsetInterceptor(conditions, generated, normed, index = [0, 1, 2, 3]),\n",
    "            SoftmaxInterceptor(conditions, generated, category, index = [(4, 3)])\n",
    "        )\n",
    "    ),\n",
    "    updater = EntropyUpdater(conditions, generated, index = [(0, 4, 3)]),\n",
    "    sampler = LoadingSampler(\n",
    "        sampler = RandomSampler(\n",
    "            data.shape[1],\n",
    "            data,\n",
    "            0.8\n",
    "        ),\n",
    "        loader = JointLoader(\n",
    "            dim,\n",
    "            loaders = (\n",
    "                StandardizeLoader(\n",
    "                    normed,\n",
    "                    data,\n",
    "                    index = [0, 1, 2, 3]\n",
    "                ),\n",
    "                CategoryLoader(\n",
    "                    category,\n",
    "                    index = [(4, 3)]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "real = connector.sample(batch)\n",
    "condition = connector.condition(real)\n",
    "fake = generator.sample(condition)\n",
    "loss = connector.loss(condition, fake)\n",
    "\n",
    "print(condition, fake, loss, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[-6.5576e-01,  1.3805e-01,  2.8974e-01, -1.8483e-02,  1.8380e-01,\n",
      "         -2.5284e-01, -5.2404e-01],\n",
      "        [ 1.4178e-01,  2.3192e-01, -7.6862e-01, -1.5927e-01, -1.9472e-01,\n",
      "         -5.9275e-01, -9.3441e-02],\n",
      "        [-1.3210e-01, -6.4582e-01, -1.6819e-01, -1.2974e-01,  6.7975e-01,\n",
      "          2.8942e-01, -1.6782e-01],\n",
      "        [-5.0830e-01, -1.4017e-01, -1.8506e-01,  6.2910e-02,  3.4650e-01,\n",
      "         -1.7748e-02, -5.0655e-01],\n",
      "        [ 7.6201e-02,  4.8606e-04, -7.1317e-01, -1.3066e-01,  2.5194e-01,\n",
      "         -4.2284e-01,  5.7424e-02],\n",
      "        [ 2.2932e-01, -2.8486e-01, -3.8343e-01, -4.6502e-01, -2.6078e-01,\n",
      "         -2.5511e-01, -2.2651e-01],\n",
      "        [-2.3805e-01,  3.7786e-01,  1.8699e-02,  3.1162e-01,  2.5627e-01,\n",
      "         -2.8903e-01, -1.6495e-02],\n",
      "        [-2.1949e-01,  8.5298e-02, -5.0670e-01, -2.5712e-01,  3.3585e-01,\n",
      "         -4.1017e-01,  1.4893e-01],\n",
      "        [ 7.5187e-01, -8.5794e-01,  7.2984e-01, -6.8622e-01,  4.1471e-01,\n",
      "         -7.6381e-03, -3.4649e-01],\n",
      "        [ 1.9328e-01, -3.7181e-01, -3.4791e-01, -4.7466e-01,  3.6930e-01,\n",
      "         -1.9275e-01, -4.0743e-01]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.0395]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Again, the `Loader` may be passed in separately\n",
    "\n",
    "generator = ResidualGenerator(\n",
    "    conditions,\n",
    "    latent,\n",
    "    generated,\n",
    "    steps = [5, 5, 5],\n",
    "    learning = 0.01,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "connector = ComposedConnector(\n",
    "    conditioner = CategoryConditioner(\n",
    "        conditions,\n",
    "        dim,\n",
    "        index = [(4, 3)],\n",
    "        samples = 1\n",
    "    ),\n",
    "    interceptor = PooledInterceptor(\n",
    "        conditions,\n",
    "        generated,\n",
    "        dim,\n",
    "        interceptors = (\n",
    "            SubsetInterceptor(conditions, generated, normed, index = [0, 1, 2, 3]),\n",
    "            SoftmaxInterceptor(conditions, generated, category, index = [(4, 3)])\n",
    "        )\n",
    "    ),\n",
    "    updater = EntropyUpdater(conditions, generated, index = [(0, 4, 3)]),\n",
    "    sampler = RandomSampler(\n",
    "        data.shape[1],\n",
    "        data,\n",
    "        0.8\n",
    "    ),\n",
    "    loader = JointLoader(\n",
    "        dim,\n",
    "        loaders = (\n",
    "            StandardizeLoader(\n",
    "                normed,\n",
    "                data,\n",
    "                index = [0, 1, 2, 3]\n",
    "            ),\n",
    "            CategoryLoader(\n",
    "                category,\n",
    "                index = [(4, 3)]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "real = connector.sample(10)\n",
    "condition = connector.condition(real)\n",
    "fake = generator.sample(condition)\n",
    "loss = connector.loss(condition, fake)\n",
    "\n",
    "print(condition, fake, loss, sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 1, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [1, 0, 0]])\n",
      "tensor([[-0.3661,  0.1997,  0.4581],\n",
      "        [ 0.4774,  0.1061,  0.1220],\n",
      "        [-0.1411, -0.1356,  0.2979],\n",
      "        [ 0.4593,  0.3745,  0.2049],\n",
      "        [ 0.7405,  0.5464,  0.5136],\n",
      "        [ 0.7230,  0.4614,  0.2779],\n",
      "        [ 0.4524,  0.2007, -0.0452],\n",
      "        [ 0.1205, -0.3172,  0.6317]], grad_fn=<TanhBackward0>)\n",
      "tensor([[0.1984, 0.3493, 0.4523],\n",
      "        [0.4183, 0.2885, 0.2932],\n",
      "        [0.2812, 0.2827, 0.4361],\n",
      "        [0.3712, 0.3410, 0.2878],\n",
      "        [0.3816, 0.3143, 0.3041],\n",
      "        [0.4148, 0.3193, 0.2658],\n",
      "        [0.4192, 0.3259, 0.2549],\n",
      "        [0.3019, 0.1949, 0.5033]], grad_fn=<CatBackward0>)\n",
      "tensor([[1.0130]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## A `Transformer` is a union class of `Conditioner`, `Interceptor`, `Updater` and `Loader`\n",
    "\n",
    "## Separate the category logic into a single `Transformer`\n",
    "\n",
    "from modugant.transformers import ComposedTransformer\n",
    "\n",
    "conditions = Dim[3](3)\n",
    "category = Dim[3](3)\n",
    "batch = Dim[8](8)\n",
    "\n",
    "transformer = ComposedTransformer(\n",
    "    conditioner = CategoryConditioner(\n",
    "        conditions,\n",
    "        category,\n",
    "        index = [(0, 3)],\n",
    "        samples = 1\n",
    "    ),\n",
    "    interceptor = SoftmaxInterceptor(conditions, category, category, index = [(0, 3)]),\n",
    "    updater = EntropyUpdater(conditions, category, index = [(0, 0, 3)]),\n",
    "    loader = CategoryLoader(\n",
    "        category,\n",
    "        index = [(4, 3)] # the index is fixed and the transformer must always load from the same index\n",
    "    )\n",
    ")\n",
    "\n",
    "# The transformer will have to be paired with a sampler to be used in the demo\n",
    "# create a sampler\n",
    "\n",
    "sampler = LoadingSampler(\n",
    "    sampler = RandomSampler(\n",
    "        data.shape[1],\n",
    "        data,\n",
    "        0.8\n",
    "    ),\n",
    "    loader = CategoryLoader(\n",
    "        category,\n",
    "        index = [(4, 3)]\n",
    "    )\n",
    ")\n",
    "\n",
    "# sample real data with the sampler\n",
    "real = sampler.sample(batch)\n",
    "# condition the real data\n",
    "condition = transformer.condition(real)\n",
    "\n",
    "# create a generator, and generate from the condition\n",
    "latent = Dim[5](5)\n",
    "generator = ResidualGenerator(\n",
    "    conditions,\n",
    "    latent,\n",
    "    category,\n",
    "    steps = [5, 5, 5],\n",
    "    learning = 0.01,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "fake = generator.sample(condition)\n",
    "# calculate the loss, calculated on the pre-prepared, generated data\n",
    "prepared = transformer.prepare(condition, fake)\n",
    "loss = transformer.loss(condition, fake)\n",
    "\n",
    "print(condition, fake, prepared, loss, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize the above transformer to use a flexible source index\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class CategoryTransformer[B: int](ComposedTransformer[B, B, B]):\n",
    "    '''Transformer for a single category'''\n",
    "    def __init__(\n",
    "        self,\n",
    "        index: Tuple[int, B] # no longer fixed to (4, 3)\n",
    "    ) -> None:\n",
    "        '''\n",
    "        Args:\n",
    "            index: The start index in the original data and the size (bins) of the category\n",
    "        '''\n",
    "        (_, bins) = index\n",
    "        super().__init__(\n",
    "            conditioner = CategoryConditioner(\n",
    "                bins,\n",
    "                bins,\n",
    "                index = [(0, bins)],\n",
    "                samples = 1\n",
    "            ),\n",
    "            interceptor = SoftmaxInterceptor(bins, bins, bins, index = [(0, bins)]),\n",
    "            updater = EntropyUpdater(bins, bins, index = [(0, 0, bins)]),\n",
    "            loader = CategoryLoader(\n",
    "                bins,\n",
    "                index = [index]\n",
    "            )\n",
    "        )\n",
    "\n",
    "bins = Dim[3](3)\n",
    "\n",
    "transformer = CategoryTransformer((4, bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2600,  0.0979, -1.2225],\n",
      "        [-0.8977, -1.2787, -0.4294],\n",
      "        [ 1.2761,  0.3273,  1.1001],\n",
      "        [ 0.5515, -0.3610,  1.0434],\n",
      "        [-0.4146,  1.0156, -1.3924],\n",
      "        [-1.0184,  1.0156, -1.3924],\n",
      "        [-1.6223, -1.7375, -1.3924],\n",
      "        [-1.1392,  0.0979, -1.2791]])\n",
      "tensor([[ 0.5428,  0.2965, -0.5407, -0.0459,  0.4075, -0.5510,  0.0584],\n",
      "        [ 0.5973,  0.2971,  0.0355, -0.6690,  0.5536, -0.1159,  0.3349],\n",
      "        [ 0.2190,  0.1934, -0.4236, -0.5345, -0.3103, -0.1656,  0.5281],\n",
      "        [ 0.4820, -0.0326, -0.2642, -0.4502,  0.1726,  0.1902, -0.0913],\n",
      "        [ 0.7294,  0.0304,  0.1852,  0.2668, -0.4797,  0.0314, -0.3606],\n",
      "        [ 0.5886, -0.2676, -0.5938,  0.2007, -0.8421, -0.7538, -0.3728],\n",
      "        [ 0.4159,  0.1454, -0.4022, -0.8561, -0.2666, -0.2447,  0.1004],\n",
      "        [ 0.6869,  0.3026,  0.3144, -0.2326,  0.5943,  0.4076, -0.2249]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([[-1.9197]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "## Combine the category transformer with a transformer to handle the non-category columns with a `JointTransformer`\n",
    "\n",
    "from modugant.transformers import JointTransformer\n",
    "\n",
    "conditions = Dim[3](3)\n",
    "latent = Dim[5](5)\n",
    "generated = Dim[7](7)\n",
    "normed = Dim[4](4)\n",
    "category = Dim[3](3)\n",
    "dim = Dim[7](7)\n",
    "batch = Dim[8](8)\n",
    "\n",
    "transformer = JointTransformer(\n",
    "    conditions,\n",
    "    generated,\n",
    "    dim,\n",
    "    transformers = (\n",
    "        CategoryTransformer((4, category)),\n",
    "        ComposedTransformer(\n",
    "            conditioner = NoneConditioner(normed),\n",
    "            interceptor = DirectInterceptor(Dim.zero(), normed),\n",
    "            loader = StandardizeLoader(\n",
    "                normed,\n",
    "                data,\n",
    "                index = [0, 1, 2, 3]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "generator = ResidualGenerator(\n",
    "    conditions,\n",
    "    latent,\n",
    "    generated,\n",
    "    steps = [5, 5, 5],\n",
    "    learning = 0.01,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "real = connector.sample(batch)\n",
    "condition = transformer.condition(real)\n",
    "fake = generator.sample(condition)\n",
    "loss = transformer.loss(condition, fake)\n",
    "\n",
    "print(condition, fake, loss, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.]])\n",
      "tensor([[ 0.1550,  0.0296, -0.5122, -0.3591, -0.1090, -0.2872, -0.5443],\n",
      "        [ 0.4830, -0.2732,  0.1904,  0.4756, -0.7595, -0.1429, -0.0110],\n",
      "        [ 0.3858,  0.2283,  0.0223,  0.3225, -0.3369, -0.0118, -0.0701],\n",
      "        [ 0.2143, -0.1070, -0.4552, -0.2396, -0.0895,  0.2283,  0.6308],\n",
      "        [ 0.2660, -0.0261, -0.5603, -0.2857,  0.2970,  0.0220,  0.6261],\n",
      "        [ 0.3247,  0.6194, -0.8044, -0.1462, -0.0805, -0.2169, -0.3734],\n",
      "        [ 0.3948,  0.2210, -0.2476, -0.3922, -0.1335, -0.0538,  0.4574],\n",
      "        [ 0.4068,  0.4317,  0.1199, -0.4742,  0.4297,  0.2258, -0.1033]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([[0.8836]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "## Create a custom transformer for standardized variables too\n",
    "\n",
    "from modugant.matrix.dim import Zero\n",
    "\n",
    "\n",
    "class StandardTransformer[D: int](ComposedTransformer[Zero, D, D]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: D,\n",
    "        index: List[int],\n",
    "        data: Tensor\n",
    "    ):\n",
    "        super().__init__(\n",
    "            conditioner = NoneConditioner(dim),\n",
    "            interceptor = DirectInterceptor(Dim.zero(), dim),\n",
    "            loader = StandardizeLoader(\n",
    "                dim,\n",
    "                data,\n",
    "                index\n",
    "            )\n",
    "        )\n",
    "\n",
    "conditions = Dim[3](3)\n",
    "latent = Dim[5](5)\n",
    "generated = Dim[7](7)\n",
    "normed = Dim[4](4)\n",
    "category = Dim[3](3)\n",
    "dim = Dim[7](7)\n",
    "batch = Dim[8](8)\n",
    "\n",
    "transformer = JointTransformer(\n",
    "    conditions,\n",
    "    generated,\n",
    "    dim,\n",
    "    transformers = (\n",
    "        StandardTransformer(\n",
    "            normed,\n",
    "            [0, 1, 2, 3],\n",
    "            data\n",
    "        ),\n",
    "        CategoryTransformer((4, category))\n",
    "    )\n",
    ")\n",
    "\n",
    "real = connector.sample(batch)\n",
    "condition = transformer.condition(real)\n",
    "fake = generator.sample(condition)\n",
    "loss = transformer.loss(condition, fake)\n",
    "\n",
    "print(condition, fake, loss, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[ 0.4688,  0.3226, -0.5319, -0.3551, -0.1758, -0.2349, -0.0621],\n",
      "        [ 0.3252,  0.3307,  0.1370, -0.0019,  0.5459, -0.0141, -0.0687],\n",
      "        [ 0.7023, -0.1541,  0.1834,  0.2219, -0.1248, -0.0142, -0.2653],\n",
      "        [ 0.2684,  0.0836, -0.7174, -0.4621, -0.5128, -0.3522,  0.0323],\n",
      "        [ 0.5215, -0.0884, -0.0687,  0.2617, -0.3020, -0.1196, -0.2039],\n",
      "        [ 0.6218, -0.1554, -0.1681, -0.1472,  0.2719, -0.0981,  0.0620],\n",
      "        [ 0.4378, -0.3567, -0.5073, -0.7531,  0.5063, -0.1242,  0.8138],\n",
      "        [ 0.5635, -0.1350, -0.1116,  0.0510, -0.0673,  0.5776,  0.1742],\n",
      "        [ 0.4128, -0.3557, -0.3664, -0.0418, -0.0978,  0.0504, -0.0813],\n",
      "        [ 0.6982,  0.1357, -0.6675, -0.2240, -0.2303,  0.3854, -0.0394]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([[ 0.4688,  0.3226, -0.5319, -0.3551,  0.3265,  0.3077,  0.3658],\n",
      "        [ 0.3252,  0.3307,  0.1370, -0.0019,  0.4735,  0.2705,  0.2561],\n",
      "        [ 0.7023, -0.1541,  0.1834,  0.2219,  0.3349,  0.3741,  0.2910],\n",
      "        [ 0.2684,  0.0836, -0.7174, -0.4621,  0.2565,  0.3012,  0.4423],\n",
      "        [ 0.5215, -0.0884, -0.0687,  0.2617,  0.3027,  0.3633,  0.3339],\n",
      "        [ 0.6218, -0.1554, -0.1681, -0.1472,  0.3998,  0.2761,  0.3241],\n",
      "        [ 0.4378, -0.3567, -0.5073, -0.7531,  0.3457,  0.1841,  0.4702],\n",
      "        [ 0.5635, -0.1350, -0.1116,  0.0510,  0.2393,  0.4560,  0.3047],\n",
      "        [ 0.4128, -0.3557, -0.3664, -0.0418,  0.3148,  0.3651,  0.3201],\n",
      "        [ 0.6982,  0.1357, -0.6675, -0.2240,  0.2462,  0.4558,  0.2980]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[1.0157]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "## Use transformers and a `Sampler` into a `Connector` with `JointConnector`\n",
    "\n",
    "from modugant.connectors.joint import JointConnector\n",
    "\n",
    "conditions = Dim[3](3)\n",
    "latent = Dim[5](5)\n",
    "generated = Dim[7](7)\n",
    "normed = Dim[4](4)\n",
    "category = Dim[3](3)\n",
    "dim = Dim[7](7)\n",
    "\n",
    "connector = JointConnector(\n",
    "    conditions,\n",
    "    generated,\n",
    "    dim,\n",
    "    transformers = (\n",
    "        StandardTransformer(\n",
    "            normed,\n",
    "            [0, 1, 2, 3],\n",
    "            data\n",
    "        ),\n",
    "        CategoryTransformer((4, category))\n",
    "    ),\n",
    "    sampler = RandomSampler( # adding a sampler allows you to extend a `Transformer` to a `Connector`\n",
    "        data.shape[1],\n",
    "        data,\n",
    "        0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "real = connector.sample(10)\n",
    "condition = connector.condition(real)\n",
    "fake = generator.sample(condition)\n",
    "prepared = connector.prepare(condition, fake)\n",
    "loss = transformer.loss(condition, fake)\n",
    "\n",
    "print(condition, fake, prepared, loss, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a category Transformer for many category variables\n",
    "\n",
    "class CategoriesTransformer[B: int](ComposedTransformer[B, B, B]):\n",
    "    '''Transformer for a single category'''\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: B, # total size now needs to be specified, and we will assert it\n",
    "        index: List[Tuple[int, int]], # take in a list of indices instead\n",
    "        samples: int = 1\n",
    "    ) -> None:\n",
    "        '''\n",
    "        Args:\n",
    "            width: The total size of the category\n",
    "            index: A list of tuples of the start index in the original data and the size (bins) of the category\n",
    "            size: The number of categories to sample\n",
    "        '''\n",
    "        sizes = [size for (_, size) in index]\n",
    "        assert sum(sizes) == width\n",
    "        ## The index and size of categories after being loaded\n",
    "        cumu = [(sum(sizes[:i]), sizes[i]) for i in range(len(index))]\n",
    "        super().__init__(\n",
    "            conditioner = CategoryConditioner(\n",
    "                width,\n",
    "                width,\n",
    "                index = cumu,\n",
    "                samples = samples\n",
    "            ),\n",
    "            interceptor = SoftmaxInterceptor(\n",
    "                width,\n",
    "                width,\n",
    "                width,\n",
    "                index = cumu\n",
    "            ),\n",
    "            updater = EntropyUpdater(\n",
    "                width,\n",
    "                width,\n",
    "                # category index and data index are the same\n",
    "                index = [(start, start, size) for (start, size) in cumu]\n",
    "            ),\n",
    "            loader = CategoryLoader(\n",
    "                width,\n",
    "                index = index\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "tensor([[ 0.2995, -0.6231, -0.2404,  0.4545, -0.0735,  0.2097,  0.1870],\n",
      "        [ 0.4885,  0.4865, -0.4001,  0.0016,  0.2716,  0.2057, -0.2418],\n",
      "        [ 0.5921, -0.2623, -0.4996,  0.6908, -0.0808, -0.1217,  0.0327],\n",
      "        [-0.2480, -0.4575,  0.3685, -0.1523, -0.3783,  0.4016,  0.4501],\n",
      "        [-0.4035,  0.1553,  0.1395,  0.1369,  0.3141, -0.5058, -0.0482],\n",
      "        [ 0.1874, -0.2999, -0.1268,  0.0325, -0.0037,  0.0482,  0.1397],\n",
      "        [ 0.2854, -0.2149, -0.1321,  0.2097, -0.0301, -0.6400, -0.3197],\n",
      "        [ 0.2982,  0.3564,  0.4817, -0.2781, -0.2323,  0.1939, -0.5306],\n",
      "        [ 0.3032,  0.1069,  0.3197,  0.0317,  0.0048,  0.1249,  0.3599],\n",
      "        [ 0.0393, -0.1071,  0.6800, -0.4833, -0.2060,  0.1421,  0.6545]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([[ 0.2995, -0.6231, -0.2404,  0.4545,  0.2759,  0.3662,  0.3580],\n",
      "        [ 0.4885,  0.4865, -0.4001,  0.0016,  0.3945,  0.3694,  0.2361],\n",
      "        [ 0.5921, -0.2623, -0.4996,  0.6908,  0.3247,  0.3116,  0.3637],\n",
      "        [-0.2480, -0.4575,  0.3685, -0.1523,  0.1828,  0.3987,  0.4185],\n",
      "        [-0.4035,  0.1553,  0.1395,  0.1369,  0.4681,  0.2062,  0.3258],\n",
      "        [ 0.1874, -0.2999, -0.1268,  0.0325,  0.3118,  0.3284,  0.3599],\n",
      "        [ 0.2854, -0.2149, -0.1321,  0.2097,  0.4363,  0.2371,  0.3266],\n",
      "        [ 0.2982,  0.3564,  0.4817, -0.2781,  0.3055,  0.4678,  0.2267],\n",
      "        [ 0.3032,  0.1069,  0.3197,  0.0317,  0.2814,  0.3173,  0.4013],\n",
      "        [ 0.0393, -0.1071,  0.6800, -0.4833,  0.2092,  0.2963,  0.4946]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[1.2567]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "## Create a custom `Connector`\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "class CustomConnector[C: int, D: int](JointConnector[C, D, D]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        conditions: C,\n",
    "        dim: D,\n",
    "        data: Tensor,\n",
    "        continuous: List[int],\n",
    "        category: List[Tuple[int, int]],\n",
    "        samples: Optional[int] = 1,\n",
    "        split: Optional[float] = 0.8,\n",
    "        sampler: Optional[Sampler[D]] = None\n",
    "    ):\n",
    "        '''\n",
    "        Custom Connector\n",
    "\n",
    "        Args:\n",
    "            conditions: The number of conditions (category bins total)\n",
    "            dim: The total dimensionality of the generated/discriminated data\n",
    "            data: The data to sample from\n",
    "            continuous: The indices of the continuous variables\n",
    "            category: The indices and sizes of the category variables\n",
    "            size: The number of categories to sample (default 1)\n",
    "            split: Optional. The proportion of data to sample (default 0.8; unused if `sampler` is provided)\n",
    "            sampler: Optional. The sampler to use (default `RandomSampler`)\n",
    "        '''\n",
    "        sizes = [size for _, size in category]\n",
    "        assert sum(sizes) == conditions\n",
    "        assert len(continuous) + conditions == dim\n",
    "        super().__init__(\n",
    "            conditions = conditions,\n",
    "            intermediates = dim,\n",
    "            outputs = dim,\n",
    "            transformers = (\n",
    "                StandardTransformer(\n",
    "                    len(continuous),\n",
    "                    continuous,\n",
    "                    data\n",
    "                ),\n",
    "                CategoriesTransformer(\n",
    "                    conditions,\n",
    "                    category,\n",
    "                    samples = samples or 1\n",
    "                )\n",
    "            ),\n",
    "            sampler = sampler or RandomSampler(\n",
    "                data.shape[1],\n",
    "                data,\n",
    "                split or 0.8\n",
    "            )\n",
    "        )\n",
    "\n",
    "latent = Dim[5](5)\n",
    "normed = Dim[4](4)\n",
    "category = Dim[3](3)\n",
    "dim = Dim[7](7)\n",
    "\n",
    "generator = ResidualGenerator(\n",
    "    category, # number of conditions\n",
    "    latent, # number of latent variables\n",
    "    dim, # number of generated variables\n",
    "    steps = [5, 5, 5],\n",
    "    learning = 0.01,\n",
    "    decay = 0.001\n",
    ")\n",
    "\n",
    "connector = CustomConnector(\n",
    "    category, # number of conditions\n",
    "    dim, # number of total variables\n",
    "    data, # data to sample from\n",
    "    [0, 1, 2, 3], # continuous variables\n",
    "    [(4, 3)], # category variables\n",
    "    samples = 1,\n",
    "    split = 0.8\n",
    ")\n",
    "\n",
    "\n",
    "real = connector.sample(10)\n",
    "condition = connector.condition(real)\n",
    "fake = generator.sample(condition)\n",
    "prepared = connector.prepare(condition, fake)\n",
    "loss = transformer.loss(condition, fake)\n",
    "\n",
    "print(condition, fake, prepared, loss, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
